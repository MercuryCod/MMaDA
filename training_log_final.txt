[2025-06-08 00:11:12,561] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-08 00:11:18,828] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /homes/55/junlin/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-06-08 00:11:19,921] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-06-08 00:11:19,922] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
00:11:20 | INFO | Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 8, 'gradient_accumulation_steps': 2, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

wandb: Currently logged in as: mercury-chang-ma (mercury-chang-ma-university-of-oxford) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignoring ID hvwqnvs9 loaded due to resume='auto' because the run ID is set to 49exk0ua.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /homes/55/junlin/MMaDA/wandb/run-20250608_001123-49exk0ua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mmada-training-t2m-instruct
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mercury-chang-ma-university-of-oxford/mmada-training-t2m
wandb: üöÄ View run at https://wandb.ai/mercury-chang-ma-university-of-oxford/mmada-training-t2m/runs/49exk0ua
  0%|          | 0/23384 [00:00<?, ?it/s]  1%|          | 236/23384 [00:00<00:09, 2349.12it/s]  2%|‚ñè         | 474/23384 [00:00<00:09, 2360.99it/s]  3%|‚ñé         | 763/23384 [00:00<00:08, 2600.61it/s]  5%|‚ñç         | 1061/23384 [00:00<00:08, 2748.09it/s]  6%|‚ñå         | 1344/23384 [00:00<00:07, 2775.87it/s]  7%|‚ñã         | 1641/23384 [00:00<00:07, 2838.41it/s]  8%|‚ñä         | 1925/23384 [00:00<00:07, 2785.50it/s]  9%|‚ñâ         | 2204/23384 [00:00<00:07, 2768.37it/s] 11%|‚ñà         | 2481/23384 [00:00<00:07, 2749.60it/s] 12%|‚ñà‚ñè        | 2769/23384 [00:01<00:07, 2787.35it/s] 13%|‚ñà‚ñé        | 3061/23384 [00:01<00:07, 2825.76it/s] 14%|‚ñà‚ñç        | 3344/23384 [00:01<00:07, 2787.27it/s] 16%|‚ñà‚ñå        | 3639/23384 [00:01<00:06, 2833.97it/s] 17%|‚ñà‚ñã        | 3923/23384 [00:01<00:06, 2784.81it/s] 18%|‚ñà‚ñä        | 4202/23384 [00:01<00:06, 2763.36it/s] 19%|‚ñà‚ñâ        | 4496/23384 [00:01<00:06, 2812.70it/s] 20%|‚ñà‚ñà        | 4788/23384 [00:01<00:06, 2841.66it/s] 22%|‚ñà‚ñà‚ñè       | 5081/23384 [00:01<00:06, 2866.17it/s] 23%|‚ñà‚ñà‚ñé       | 5368/23384 [00:01<00:06, 2804.41it/s] 24%|‚ñà‚ñà‚ñç       | 5662/23384 [00:02<00:06, 2843.94it/s] 25%|‚ñà‚ñà‚ñå       | 5955/23384 [00:02<00:06, 2868.03it/s] 27%|‚ñà‚ñà‚ñã       | 6243/23384 [00:02<00:06, 2822.19it/s] 28%|‚ñà‚ñà‚ñä       | 6534/23384 [00:02<00:05, 2847.75it/s] 29%|‚ñà‚ñà‚ñâ       | 6820/23384 [00:02<00:05, 2807.19it/s] 30%|‚ñà‚ñà‚ñà       | 7102/23384 [00:02<00:06, 2621.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 7396/23384 [00:02<00:05, 2710.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 7672/23384 [00:02<00:05, 2724.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 7950/23384 [00:02<00:05, 2739.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 8226/23384 [00:02<00:05, 2638.80it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 8516/23384 [00:03<00:05, 2713.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 8806/23384 [00:03<00:05, 2765.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 9084/23384 [00:03<00:05, 2746.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 9369/23384 [00:03<00:05, 2775.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9648/23384 [00:03<00:04, 2777.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9931/23384 [00:03<00:04, 2792.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10211/23384 [00:03<00:04, 2763.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10488/23384 [00:03<00:04, 2742.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10776/23384 [00:03<00:04, 2781.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11062/23384 [00:03<00:04, 2803.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11358/23384 [00:04<00:04, 2847.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11643/23384 [00:04<00:04, 2844.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 11930/23384 [00:04<00:04, 2851.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12216/23384 [00:04<00:03, 2850.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12502/23384 [00:04<00:03, 2831.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12786/23384 [00:04<00:03, 2799.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13067/23384 [00:04<00:03, 2772.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13345/23384 [00:04<00:03, 2753.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13631/23384 [00:04<00:03, 2783.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 13921/23384 [00:05<00:03, 2818.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14207/23384 [00:05<00:03, 2828.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14491/23384 [00:05<00:03, 2830.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 14775/23384 [00:05<00:03, 2791.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15055/23384 [00:05<00:02, 2787.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15334/23384 [00:05<00:03, 2604.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15619/23384 [00:05<00:02, 2672.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 15889/23384 [00:05<00:02, 2659.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16172/23384 [00:05<00:02, 2708.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16454/23384 [00:05<00:02, 2740.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 16729/23384 [00:06<00:02, 2697.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17017/23384 [00:06<00:02, 2749.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17308/23384 [00:06<00:02, 2794.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 17588/23384 [00:06<00:02, 2753.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 17882/23384 [00:06<00:01, 2805.02it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18163/23384 [00:06<00:01, 2755.60it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18439/23384 [00:06<00:01, 2732.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 18732/23384 [00:06<00:01, 2789.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19028/23384 [00:06<00:01, 2837.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19322/23384 [00:06<00:01, 2864.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 19626/23384 [00:07<00:01, 2915.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 19918/23384 [00:07<00:01, 2908.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20209/23384 [00:07<00:01, 2797.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 20490/23384 [00:07<00:01, 2767.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 20782/23384 [00:07<00:00, 2810.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21074/23384 [00:07<00:00, 2839.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21359/23384 [00:07<00:00, 2837.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 21644/23384 [00:07<00:00, 2767.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 21926/23384 [00:07<00:00, 2781.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22208/23384 [00:07<00:00, 2790.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22496/23384 [00:08<00:00, 2816.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 22789/23384 [00:08<00:00, 2848.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23079/23384 [00:08<00:00, 2863.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23366/23384 [00:08<00:00, 2863.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23384/23384 [00:08<00:00, 2783.01it/s]
  0%|          | 0/1460 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 170/1460 [00:00<00:00, 1695.83it/s] 25%|‚ñà‚ñà‚ñç       | 358/1460 [00:00<00:00, 1801.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 542/1460 [00:00<00:00, 1815.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 724/1460 [00:00<00:00, 1753.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 907/1460 [00:00<00:00, 1779.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1086/1460 [00:00<00:00, 1758.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1263/1460 [00:00<00:00, 1762.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1440/1460 [00:00<00:00, 1727.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [00:00<00:00, 1751.48it/s]
Pointer Pointing at 0
Reading checkpoints/t2m/Comp_v6_KLD005/opt.txt
Loading Evaluation Model Wrapper (Epoch 28) Completed!!
00:11:39 | INFO | loading checkpoint from output/VQVAE/net_last.pth
  0%|          | 0/23384 [00:00<?, ?it/s]  1%|          | 252/23384 [00:00<00:09, 2511.14it/s]  2%|‚ñè         | 507/23384 [00:00<00:09, 2530.32it/s]  3%|‚ñé         | 761/23384 [00:00<00:09, 2442.36it/s]  4%|‚ñç         | 1006/23384 [00:00<00:09, 2440.02it/s]  5%|‚ñå         | 1252/23384 [00:00<00:09, 2446.76it/s]  6%|‚ñã         | 1497/23384 [00:00<00:09, 2408.33it/s]  7%|‚ñã         | 1743/23384 [00:00<00:08, 2422.78it/s]  8%|‚ñä         | 1986/23384 [00:00<00:08, 2402.07it/s] 10%|‚ñâ         | 2233/23384 [00:00<00:08, 2419.79it/s] 11%|‚ñà         | 2476/23384 [00:01<00:08, 2413.29it/s] 12%|‚ñà‚ñè        | 2727/23384 [00:01<00:08, 2441.08it/s] 13%|‚ñà‚ñé        | 2978/23384 [00:01<00:08, 2459.02it/s] 14%|‚ñà‚ñç        | 3224/23384 [00:01<00:08, 2436.27it/s] 15%|‚ñà‚ñç        | 3468/23384 [00:01<00:08, 2382.15it/s] 16%|‚ñà‚ñå        | 3709/23384 [00:01<00:08, 2388.57it/s] 17%|‚ñà‚ñã        | 3956/23384 [00:01<00:08, 2410.89it/s] 18%|‚ñà‚ñä        | 4218/23384 [00:01<00:07, 2472.50it/s] 19%|‚ñà‚ñâ        | 4472/23384 [00:01<00:07, 2492.20it/s] 20%|‚ñà‚ñà        | 4731/23384 [00:01<00:07, 2521.36it/s] 21%|‚ñà‚ñà‚ñè       | 4985/23384 [00:02<00:07, 2525.91it/s] 22%|‚ñà‚ñà‚ñè       | 5238/23384 [00:02<00:07, 2452.20it/s] 23%|‚ñà‚ñà‚ñé       | 5484/23384 [00:02<00:07, 2395.01it/s] 24%|‚ñà‚ñà‚ñç       | 5725/23384 [00:02<00:07, 2374.23it/s] 26%|‚ñà‚ñà‚ñå       | 5963/23384 [00:02<00:11, 1517.96it/s] 26%|‚ñà‚ñà‚ñã       | 6183/23384 [00:02<00:10, 1660.79it/s] 27%|‚ñà‚ñà‚ñã       | 6399/23384 [00:02<00:09, 1775.41it/s] 28%|‚ñà‚ñà‚ñä       | 6635/23384 [00:02<00:08, 1919.83it/s] 29%|‚ñà‚ñà‚ñâ       | 6863/23384 [00:03<00:08, 2013.68it/s] 30%|‚ñà‚ñà‚ñà       | 7090/23384 [00:03<00:07, 2082.34it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 7333/23384 [00:03<00:07, 2178.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 7561/23384 [00:03<00:07, 2190.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 7810/23384 [00:03<00:06, 2276.57it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 8043/23384 [00:03<00:06, 2270.05it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 8287/23384 [00:03<00:06, 2319.57it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 8532/23384 [00:03<00:06, 2357.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 8770/23384 [00:03<00:06, 2329.47it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 9016/23384 [00:03<00:06, 2365.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 9262/23384 [00:04<00:05, 2390.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 9507/23384 [00:04<00:05, 2405.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9749/23384 [00:04<00:05, 2331.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 9998/23384 [00:04<00:05, 2374.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10237/23384 [00:04<00:05, 2293.44it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10468/23384 [00:04<00:05, 2251.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10704/23384 [00:04<00:05, 2281.19it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 10933/23384 [00:04<00:05, 2232.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11157/23384 [00:04<00:05, 2197.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11392/23384 [00:05<00:05, 2240.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11617/23384 [00:05<00:05, 2171.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 11839/23384 [00:05<00:05, 2184.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12058/23384 [00:05<00:05, 2116.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12271/23384 [00:05<00:05, 2064.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12478/23384 [00:05<00:05, 2020.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12681/23384 [00:05<00:05, 1992.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 12881/23384 [00:05<00:05, 1980.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13080/23384 [00:05<00:05, 1967.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13277/23384 [00:05<00:05, 1921.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13470/23384 [00:06<00:05, 1902.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13667/23384 [00:06<00:05, 1920.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 13864/23384 [00:06<00:04, 1933.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14058/23384 [00:06<00:04, 1932.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14252/23384 [00:06<00:04, 1930.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14446/23384 [00:06<00:06, 1473.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 14640/23384 [00:06<00:05, 1587.23it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 14848/23384 [00:06<00:04, 1713.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15042/23384 [00:06<00:04, 1773.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15233/23384 [00:07<00:04, 1809.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15441/23384 [00:07<00:04, 1884.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15635/23384 [00:07<00:04, 1899.73it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 15842/23384 [00:07<00:03, 1947.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16044/23384 [00:07<00:03, 1966.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16262/23384 [00:07<00:03, 2028.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16477/23384 [00:07<00:03, 2062.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 16685/23384 [00:07<00:03, 2029.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 16889/23384 [00:07<00:03, 2027.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17101/23384 [00:07<00:03, 2052.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17323/23384 [00:08<00:02, 2099.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17534/23384 [00:08<00:02, 2101.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 17745/23384 [00:08<00:02, 2079.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 17955/23384 [00:08<00:02, 2084.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18164/23384 [00:08<00:02, 2083.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18374/23384 [00:08<00:02, 2088.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18583/23384 [00:08<00:02, 2082.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 18794/23384 [00:08<00:02, 2088.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19005/23384 [00:08<00:02, 2092.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19218/23384 [00:08<00:01, 2101.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19437/23384 [00:09<00:01, 2127.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 19650/23384 [00:09<00:01, 2101.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 19861/23384 [00:09<00:01, 2075.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20069/23384 [00:09<00:01, 2052.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20275/23384 [00:09<00:01, 2018.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 20477/23384 [00:09<00:01, 2017.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 20682/23384 [00:09<00:01, 2026.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 20885/23384 [00:09<00:01, 2010.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21087/23384 [00:09<00:01, 2002.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21295/23384 [00:10<00:01, 2022.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21526/23384 [00:10<00:00, 2106.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 21747/23384 [00:10<00:00, 2137.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 21961/23384 [00:10<00:00, 2106.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22172/23384 [00:10<00:00, 2106.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22397/23384 [00:10<00:00, 2147.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 22619/23384 [00:10<00:00, 2168.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 22837/23384 [00:10<00:00, 2171.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23055/23384 [00:10<00:00, 2170.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23273/23384 [00:10<00:00, 2121.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23384/23384 [00:10<00:00, 2128.58it/s]
self.sptids_dict: {'<|soi|>': tensor([126084]), '<|eoi|>': tensor([126085]), '<|sov|>': tensor([126086]), '<|eov|>': tensor([126087]), '<|t2i|>': tensor([126088]), '<|mmu|>': tensor([126089]), '<|t2v|>': tensor([126090]), '<|v2v|>': tensor([126091]), '<|lvg|>': tensor([126092]), '[iPAD]': tensor([126093]), '<|r2i|>': tensor([126094]), '<|t2m|>': tensor([126095]), '<|som|>': tensor([126096]), '<|eom|>': tensor([126097]), '<|sot|>': tensor([126080]), '<|eot|>': tensor([126081]), '<|end_header_id|>': tensor([126347]), '<|eot_id|>': tensor([126348]), '<|start_header_id|>': tensor([126346])}
special tokens : 
 {'<|soi|>': tensor([126084]), '<|eoi|>': tensor([126085]), '<|sov|>': tensor([126086]), '<|eov|>': tensor([126087]), '<|t2i|>': tensor([126088]), '<|mmu|>': tensor([126089]), '<|t2v|>': tensor([126090]), '<|v2v|>': tensor([126091]), '<|lvg|>': tensor([126092]), '[iPAD]': tensor([126093]), '<|r2i|>': tensor([126094]), '<|t2m|>': tensor([126095]), '<|som|>': tensor([126096]), '<|eom|>': tensor([126097]), '<|sot|>': tensor([126080]), '<|eot|>': tensor([126081]), '<|end_header_id|>': tensor([126347]), '<|eot_id|>': tensor([126348]), '<|start_header_id|>': tensor([126346])}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[2025-06-08 00:11:54,846] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 1
Initializing MMadaModelLM with config: MMadaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "Gen-Verse/MMaDA-8B-MixCoT",
  "activation_type": "silu",
  "alibi": false,
  "alibi_bias_max": 8.0,
  "architectures": [
    "LLaDAModelLM"
  ],
  "attention_dropout": 0.0,
  "attention_layer_norm": false,
  "attention_layer_norm_with_affine": true,
  "auto_map": {
    "AutoConfig": "Gen-Verse/MMaDA-8B-MixCoT--configuration_llada.LLaDAConfig",
    "AutoModel": "Gen-Verse/MMaDA-8B-MixCoT--modeling_llada.LLaDAModelLM",
    "AutoModelForCausalLM": "Gen-Verse/MMaDA-8B-MixCoT--modeling_llada.LLaDAModelLM"
  },
  "bias_for_layer_norm": false,
  "block_group_size": 1,
  "block_type": "llama",
  "codebook_size": 512,
  "d_model": 4096,
  "embedding_dropout": 0.0,
  "embedding_size": 134656,
  "eos_token_id": 126081,
  "flash_attention": false,
  "include_bias": false,
  "include_qkv_bias": false,
  "init_cutoff_factor": null,
  "init_device": "meta",
  "init_fn": "mitchell",
  "init_std": 0.02,
  "input_emb_norm": false,
  "layer_norm_type": "rms",
  "layer_norm_with_affine": true,
  "llm_vocab_size": 126464,
  "mask_token_id": 126336,
  "max_sequence_length": 4096,
  "mlp_hidden_size": 12288,
  "mlp_ratio": 4,
  "model_type": "mmada",
  "multi_query_attention": null,
  "n_heads": 32,
  "n_kv_heads": 32,
  "n_layers": 32,
  "new_vocab_size": 134659,
  "num_new_special_tokens": 3,
  "num_vq_tokens": 256,
  "pad_token_id": 126081,
  "precision": "amp_bf16",
  "pretrained_model_path": "Gen-Verse/MMaDA-8B-MixCoT",
  "residual_dropout": 0.0,
  "rms_norm_eps": 1e-05,
  "rope": true,
  "rope_full_precision": true,
  "rope_theta": 500000.0,
  "scale_logits": false,
  "tie_word_embeddings": false,
  "tokenizer_path": "GSAI-ML/LLaDA-8B-Instruct",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.0",
  "use_cache": false,
  "vocab_size": 134656,
  "w_clip_vit": false,
  "weight_tying": false
}

[2025-06-08 00:11:58,253] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 8.08B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.57s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:03,  1.59s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.58s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.20s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.34s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Installed CUDA version 12.1 does not match the version torch was compiled with 12.6 but since the APIs are compatible, accepting this combination
Using /homes/55/junlin/.cache/torch_extensions/py310_cu126 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /homes/55/junlin/.cache/torch_extensions/py310_cu126/cpu_adam/build.ninja...
/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 0.23534560203552246 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1
[2025-06-08 00:12:29,253] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.9, git-hash=unknown, git-branch=unknown
[2025-06-08 00:12:29,253] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 1
[2025-06-08 00:12:29,264] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-08 00:12:29,265] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-06-08 00:12:29,265] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-08 00:12:29,274] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2025-06-08 00:12:29,274] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2025-06-08 00:12:29,274] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-06-08 00:12:29,274] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-06-08 00:12:29,914] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[2025-06-08 00:12:29,915] [INFO] [utils.py:782:see_memory_usage] MA 2.22 GB         Max_MA 7.48 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:29,915] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 28.35 GB, percent = 5.6%
[2025-06-08 00:12:29,917] [INFO] [stage3.py:170:__init__] Reduce bucket size 500000000
[2025-06-08 00:12:29,917] [INFO] [stage3.py:171:__init__] Prefetch bucket size 50000000
[2025-06-08 00:12:30,211] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-06-08 00:12:30,212] [INFO] [utils.py:782:see_memory_usage] MA 2.22 GB         Max_MA 2.22 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:30,212] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 28.35 GB, percent = 5.6%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2025-06-08 00:12:30,962] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-06-08 00:12:30,963] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 2.22 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:30,963] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 30.41 GB, percent = 6.0%
[2025-06-08 00:12:31,275] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[2025-06-08 00:12:31,276] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:31,276] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 30.41 GB, percent = 6.0%
/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[2025-06-08 00:12:36,204] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 8
[2025-06-08 00:12:36,205] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:36,206] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 31.74 GB, percent = 6.3%
[2025-06-08 00:12:36,503] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[2025-06-08 00:12:36,504] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:36,504] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 31.74 GB, percent = 6.3%
[2025-06-08 00:12:37,585] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[2025-06-08 00:12:37,586] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:37,586] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.98 GB, percent = 12.3%
[2025-06-08 00:12:37,872] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-06-08 00:12:37,873] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:37,873] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.95 GB, percent = 12.3%
[2025-06-08 00:12:38,542] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-06-08 00:12:38,543] [INFO] [utils.py:782:see_memory_usage] MA 0.16 GB         Max_MA 0.16 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:38,543] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 92.08 GB, percent = 18.3%
[2025-06-08 00:12:38,544] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
[2025-06-08 00:12:39,731] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-06-08 00:12:39,732] [INFO] [utils.py:782:see_memory_usage] MA 1.1 GB         Max_MA 3.15 GB         CA 9.5 GB         Max_CA 9 GB 
[2025-06-08 00:12:39,733] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 107.16 GB, percent = 21.3%
[2025-06-08 00:12:39,733] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[2025-06-08 00:12:39,733] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-06-08 00:12:39,734] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-08 00:12:39,734] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2025-06-08 00:12:39,735] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[2025-06-08 00:12:39,735] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-08 00:12:39,736] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-06-08 00:12:39,736] [INFO] [config.py:1007:print]   amp_enabled .................. False
[2025-06-08 00:12:39,736] [INFO] [config.py:1007:print]   amp_params ................... False
[2025-06-08 00:12:39,736] [INFO] [config.py:1007:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6a9cbf09d0>
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   communication_data_type ...... None
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[2025-06-08 00:12:39,737] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-08 00:12:39,738] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[2025-06-08 00:12:39,738] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[2025-06-08 00:12:39,738] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-08 00:12:39,738] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   disable_allgather ............ False
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   dump_state ................... False
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[2025-06-08 00:12:39,739] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[2025-06-08 00:12:39,740] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   global_rank .................. 0
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 2
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[2025-06-08 00:12:39,741] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[2025-06-08 00:12:39,742] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[2025-06-08 00:12:39,742] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[2025-06-08 00:12:39,742] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[2025-06-08 00:12:39,742] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-06-08 00:12:39,743] [INFO] [config.py:1007:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-08 00:12:39,743] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[2025-06-08 00:12:39,743] [INFO] [config.py:1007:print]   optimizer_name ............... None
[2025-06-08 00:12:39,743] [INFO] [config.py:1007:print]   optimizer_params ............. None
[2025-06-08 00:12:39,743] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   pld_enabled .................. False
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   pld_params ................... False
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   scheduler_name ............... None
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   scheduler_params ............. None
[2025-06-08 00:12:39,744] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   sparse_attention ............. None
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   steps_per_print .............. inf
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[2025-06-08 00:12:39,745] [INFO] [config.py:1007:print]   train_batch_size ............. 16
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  8
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   world_size ................... 1
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  True
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-06-08 00:12:39,746] [INFO] [config.py:1007:print]   zero_enabled ................. True
[2025-06-08 00:12:39,747] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-08 00:12:39,747] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[2025-06-08 00:12:39,747] [INFO] [config.py:993:print_user_config]   json = {
    "train_batch_size": 16, 
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 2, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "cpu", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "cpu", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
00:12:41 | INFO | ***** Train Text-to-Motion *****
evaluation_mmada_t2m
00:13:07 | INFO | Starting evaluation with motion_vocab_size=512
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [142,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [140,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [56,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [98,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
00:13:54 | WARNING | Embedding extraction failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

00:13:54 | WARNING | Ground truth processing failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

00:13:54 | ERROR | Generation failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/homes/55/junlin/MMaDA/utils/eval_trans.py", line 661, in evaluation_mmada_t2m
    dummy_motion_tokens = torch.full(
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/homes/55/junlin/MMaDA/training/train_t2m.py", line 517, in <module>
    main()
  File "/homes/55/junlin/MMaDA/training/train_t2m.py", line 439, in main
    eval_trans.evaluation_mmada_t2m(
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/homes/55/junlin/MMaDA/utils/eval_trans.py", line 690, in evaluation_mmada_t2m
    pred_pose = torch.zeros((bs, motion_seq_len, pose.shape[-1]), device=mmada_model.device)
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank0]: Traceback (most recent call last):
[rank0]:   File "/homes/55/junlin/MMaDA/utils/eval_trans.py", line 661, in evaluation_mmada_t2m
[rank0]:     dummy_motion_tokens = torch.full(
[rank0]: RuntimeError: CUDA error: device-side assert triggered
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/homes/55/junlin/MMaDA/training/train_t2m.py", line 517, in <module>
[rank0]:     main()
[rank0]:   File "/homes/55/junlin/MMaDA/training/train_t2m.py", line 439, in main
[rank0]:     eval_trans.evaluation_mmada_t2m(
[rank0]:   File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/homes/55/junlin/MMaDA/utils/eval_trans.py", line 690, in evaluation_mmada_t2m
[rank0]:     pred_pose = torch.zeros((bs, motion_seq_len, pose.shape[-1]), device=mmada_model.device)
[rank0]: RuntimeError: CUDA error: device-side assert triggered
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mmmada-training-t2m-instruct[0m at: [34mhttps://wandb.ai/mercury-chang-ma-university-of-oxford/mmada-training-t2m/runs/49exk0ua[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250608_001123-49exk0ua/logs[0m
E0608 00:14:08.245000 48069 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 48373) of binary: /homes/55/junlin/miniconda3/envs/mmada/bin/python3.10
Warning: The cache directory for DeepSpeed Triton autotune, /homes/55/junlin/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Traceback (most recent call last):
  File "/homes/55/junlin/miniconda3/envs/mmada/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1183, in launch_command
    deepspeed_launcher(args)
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/accelerate/commands/launch.py", line 868, in deepspeed_launcher
    distrib_run.run(args)
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/homes/55/junlin/miniconda3/envs/mmada/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
training/train_t2m.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-06-08_00:14:08
  host      : torrnode11.priv
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 48373)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
